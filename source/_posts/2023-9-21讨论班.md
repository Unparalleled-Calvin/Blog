---
title: 2023-9-21讨论班
tags: [Fuzz, LLM, DM]
categories: [组会记录]
date: 2023-09-21 19:06:42
---

### Large Language Models are Edge-Case Fuzzers: Testing Deep Learning Libraries via FuzzGPT

Edge-Case/Conner-Case 不常见的样例

用的是codex，chatgpt在代码上训练的模型；以及codegen

- zero-shot：啥也不给，只让它生成Edge Case
- few-shot：开孔填空，在code上按照一定的pattern挖洞，然后让llm补充，循环进行
- fine-tune：喂数据，从pr里拉之前容易引发bug的代码，人先标注有限的case，然后作为prompt提供给大模型

### Marlin: A Concurrent and Write-Optimized B+-tree Index on Disaggregated Memory (ICPP'23)

在DM上高性能B+树索引

- Insert/Delete/Update 并发控制开销大（锁的粒度不够小）
  - 这篇文章将叶子上的的kv改成key+pointer以避免在index上阻塞地写数据=>只要先准备好数据，快速地改pointer就行了。而这就牺牲了范围查询地效率，因为每次根据pointer查具体的内存位置都要走一次index
- Structural Modification Operation和IDU的同步导致效率低
  - FAA三状态锁区分SMO和IDU--每个叶子上有一个SMO独占+IDU共享锁
  - FAA：Fetch and Add, return last value，CAS：Compare and Swap
  - 锁值为0是S0，>=1是S1，<-T是S2
  - SMO会将锁减去一个值X(X must > T)，根据返回值确定目前是其他SMO（发现返回值为负的，rollback+X，不会改变S2状态）还是其他IDU（rollback+X，不会影响S1状态，重读直到返回值为0，即所有IDU在锁上加上的1都被还回去了）
- 每次IDU都要多次RDMA
  - 压缩写操作的关键路径，读叶子的时候“投机地”用FAA上锁（猜对了少一个RTT，猜错了多一个RTT，由于概率原因还是有收益的）
  - 由于投机了，所以可以batch发送

